{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /workspaces/shap-authorship-analysis-demo\n",
      "Path: dump/text_data = /workspaces/shap-authorship-analysis-demo/dump/text_data\n",
      "Path: dump/dataset = /workspaces/shap-authorship-analysis-demo/dump/dataset\n",
      "Path: data/john_blake_2023/wordLists/adjectivesPastParticiple = /workspaces/shap-authorship-analysis-demo/data/john_blake_2023/wordLists/adjectivesPastParticiple\n",
      "Path: dump/lgbm/model = /workspaces/shap-authorship-analysis-demo/dump/lgbm/model\n",
      "Path: dump/shap/figure = /workspaces/shap-authorship-analysis-demo/dump/shap/figure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vscode/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import Final, assert_type\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from authorship_tool.types_ import Para2dStr, Tag\n",
    "from authorship_tool.util.feature.dataset_generator import (\n",
    "    ParagraphFeatureDatasetGenerator,\n",
    ")\n",
    "from authorship_tool.util.feature.pos import PosFeature\n",
    "from authorship_tool.util.path_util import PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide=\"call\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = PATHS[\"dataset_dump_dir\"].joinpath(\"manual\")\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras_a: list[Para2dStr] = []\n",
    "assert_type(paras_a, list[Para2dStr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras_b: list[Para2dStr] = []\n",
    "assert_type(paras_b, list[Para2dStr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "src type is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m all_paras: \u001b[38;5;28mlist\u001b[39m[Para2dStr] \u001b[38;5;241m=\u001b[39m paras_a \u001b[38;5;241m+\u001b[39m paras_b\n\u001b[0;32m----> 2\u001b[0m all_pos: \u001b[38;5;28mtuple\u001b[39m[Tag, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mPosFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_paras\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtag_subcategories()\u001b[38;5;241m.\u001b[39mall_pos\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_pos)\n",
      "File \u001b[0;32m/workspaces/shap-authorship-analysis-demo/authorship_tool/util/feature/pos.py:49\u001b[0m, in \u001b[0;36mPosFeature.__init__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m     46\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m words\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tagged_tokens) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m type_guard\u001b[38;5;241m.\u001b[39mare_tagged_tokens(tagged_tokens):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc type is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__tagged_tokens: Final[\u001b[38;5;28mlist\u001b[39m[TaggedToken]] \u001b[38;5;241m=\u001b[39m tagged_tokens\n",
      "\u001b[0;31mTypeError\u001b[0m: src type is not supported."
     ]
    }
   ],
   "source": [
    "all_paras: list[Para2dStr] = paras_a + paras_b\n",
    "all_pos: tuple[Tag, ...] = PosFeature(all_paras).tag_subcategories().all_pos\n",
    "print(all_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = ParagraphFeatureDatasetGenerator(tags=all_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_ans_pairs: tuple[tuple[Para2dStr, np.bool_], ...] = tuple(\n",
    "    (para, np.bool_(True)) for para in paras_a\n",
    ") + tuple((para, np.bool_(False)) for para in paras_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tuple = tuple(\n",
    "    dataset_generator.generate_from_paragraph(para, answer)\n",
    "    for para, answer in para_ans_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets: pd.DataFrame = pd.concat(dataset_tuple, axis=1).reset_index(drop=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.columns = (*dataset_generator.columns, \"answer\")\n",
    "for col, dtype in zip(\n",
    "    datasets.columns,\n",
    "    dataset_generator.dtypes + [bool],\n",
    "    strict=True,\n",
    "):\n",
    "    datasets[col] = datasets[col].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(datasets.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.to_csv(dataset_dir.joinpath(\"dataset.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
