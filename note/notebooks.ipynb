{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents: list[str] = [\n",
    "    \"It is obvious that you have been misled.\",\n",
    "    \"It's a shame what happened to you and your sister\",\n",
    "    \"It might be a good idea to wear a respirator mask when you're working with fiberglass.\",\n",
    "    \"It's likely that the enemy simply dropped back off the hilltop once they'd grabbed all the weapons they could carry.\",\n",
    "    \"It surprised everybody that Marlene had so much energy and strength.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('is', 'VBZ'), ('obvious', 'JJ'), ('that', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('been', 'VBN'), ('misled', 'VBN'), ('.', '.')]\n",
      "[('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('shame', 'NN'), ('what', 'WDT'), ('happened', 'VBD'), ('to', 'TO'), ('you', 'PRP'), ('and', 'CC'), ('your', 'PRP$'), ('sister', 'NN')]\n",
      "[('It', 'PRP'), ('might', 'MD'), ('be', 'VB'), ('a', 'DT'), ('good', 'JJ'), ('idea', 'NN'), ('to', 'TO'), ('wear', 'VB'), ('a', 'DT'), ('respirator', 'NN'), ('mask', 'NN'), ('when', 'WRB'), ('you', 'PRP'), (\"'re\", 'VBP'), ('working', 'VBG'), ('with', 'IN'), ('fiberglass', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), (\"'s\", 'VBZ'), ('likely', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('enemy', 'NN'), ('simply', 'RB'), ('dropped', 'VBD'), ('back', 'RB'), ('off', 'IN'), ('the', 'DT'), ('hilltop', 'NN'), ('once', 'IN'), ('they', 'PRP'), (\"'d\", 'MD'), ('grabbed', 'VB'), ('all', 'PDT'), ('the', 'DT'), ('weapons', 'NNS'), ('they', 'PRP'), ('could', 'MD'), ('carry', 'VB'), ('.', '.')]\n",
      "[('It', 'PRP'), ('surprised', 'VBD'), ('everybody', 'NN'), ('that', 'IN'), ('Marlene', 'NNP'), ('had', 'VBD'), ('so', 'RB'), ('much', 'JJ'), ('energy', 'NN'), ('and', 'CC'), ('strength', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: It is obvious that you have been misled.\n",
      "Updated Tags: [('It', 'PRP'), ('is', 'VBZ'), ('obvious', 'JJ_exp'), ('that', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('been', 'VBN'), ('misled', 'VBN'), ('.', '.')]\n",
      "\n",
      "Sentence: It's a shame what happened to you and your sister\n",
      "Updated Tags: [('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('shame', 'NN'), ('what', 'WDT'), ('happened', 'VBD'), ('to', 'TO'), ('you', 'PRP'), ('and', 'CC'), ('your', 'PRP$'), ('sister', 'NN')]\n",
      "\n",
      "Sentence: It might be a good idea to wear a respirator mask when you're working with fiberglass.\n",
      "Updated Tags: [('It', 'PRP'), ('might', 'MD'), ('be', 'VB'), ('a', 'DT'), ('good', 'JJ_exp'), ('idea', 'NN'), ('to', 'TO'), ('wear', 'VB'), ('a', 'DT'), ('respirator', 'NN'), ('mask', 'NN'), ('when', 'WRB'), ('you', 'PRP'), (\"'re\", 'VBP'), ('working', 'VBG'), ('with', 'IN'), ('fiberglass', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence: It's likely that the enemy simply dropped back off the hilltop once they'd grabbed all the weapons they could carry.\n",
      "Updated Tags: [('It', 'PRP'), (\"'s\", 'VBZ'), ('likely', 'JJ_exp'), ('that', 'IN'), ('the', 'DT'), ('enemy', 'NN'), ('simply', 'RB'), ('dropped', 'VBD'), ('back', 'RB'), ('off', 'IN'), ('the', 'DT'), ('hilltop', 'NN'), ('once', 'IN'), ('they', 'PRP'), (\"'d\", 'MD'), ('grabbed', 'VB'), ('all', 'PDT'), ('the', 'DT'), ('weapons', 'NNS'), ('they', 'PRP'), ('could', 'MD'), ('carry', 'VB'), ('.', '.')]\n",
      "\n",
      "Sentence: It surprised everybody that Marlene had so much energy and strength.\n",
      "Updated Tags: [('It', 'PRP'), ('surprised', 'VBD'), ('everybody', 'NN'), ('that', 'IN'), ('Marlene', 'NNP'), ('had', 'VBD'), ('so', 'RB'), ('much', 'JJ'), ('energy', 'NN'), ('and', 'CC'), ('strength', 'NN'), ('.', '.')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vscode/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum, auto\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Make sure NLTK's resources are downloaded\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "class State(Enum):\n",
    "    INITIAL = auto()\n",
    "    FOUND_IT = auto()\n",
    "    FOUND_VERB = auto()\n",
    "    FOUND_ADJ = auto()\n",
    "    FOUND_THAT_TO = auto()\n",
    "\n",
    "\n",
    "extraposition_adjective_list = [\"obvious\", \"shame\", \"good\", \"likely\", \"surprised\"]\n",
    "\n",
    "\n",
    "def tag_extraposed_adjectives(sentence):\n",
    "    state = State.INITIAL\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    for i, (word, tag) in enumerate(tagged_tokens):\n",
    "        if state == State.INITIAL and word.lower() == \"it\":\n",
    "            state = State.FOUND_IT\n",
    "        elif state == State.FOUND_IT and tag.startswith(\"V\"):\n",
    "            state = State.FOUND_VERB\n",
    "        elif (\n",
    "            state == State.FOUND_VERB\n",
    "            and tag == \"JJ\"\n",
    "            and word.lower() in extraposition_adjective_list\n",
    "        ):\n",
    "            state = State.FOUND_ADJ\n",
    "            tagged_tokens[i] = (word, \"JJ_exp\")  # Update tag to JJ_exp\n",
    "            state = State.INITIAL  # Reset state for next adjective\n",
    "        elif state == State.FOUND_ADJ and word.lower() in [\"that\", \"to\"]:\n",
    "            state = State.FOUND_THAT_TO\n",
    "        elif word in [\".\", \"?\", \"!\"]:\n",
    "            state = State.INITIAL  # Reset state for sentences ending\n",
    "\n",
    "    return tagged_tokens\n",
    "\n",
    "# Apply the function and print results\n",
    "for sentence in sents:\n",
    "    tagged_tokens = tag_extraposed_adjectives(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(\"Updated Tags:\", tagged_tokens)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
